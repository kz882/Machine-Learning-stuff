{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "\n",
    "Feel free to use this notebook as your report for the whole 4th task of the homework. In other words, you can plot curves, print out results right here, no need to put it in the pdf (though you can if you want!). Just make sure that you **discuss**/**describe** your results somewhere.\n",
    "\n",
    "Please keep in mind that\n",
    "***all the numbers/results given in your report here should be reproducible by us***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Logistic regression with SciKit Learn\n",
    "\n",
    "In the first part of this practical section you have to implement *logistic regression classifier* using *scikit* learn library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Please use make_blob function as we did in the lab to produce some random datasets. Consider giving us a random_seed which you will use while reporting results in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting make_blobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement make_blobs (from versions: )\n",
      "No matching distribution found for make_blobs\n"
     ]
    }
   ],
   "source": [
    "!pip install make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAKE A DATASET HERE ###\n",
    "from sklearn.datasets.samples_generator import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "from tqdm import tqdm\n",
    "\n",
    "#random_seed = numpy.random.randint(0,100)\n",
    "random_seed = 65\n",
    "\n",
    "x, y = make_blobs(n_samples=2000, centers=2, n_features=2,\n",
    "                  random_state=random_seed)\n",
    "\n",
    "plot.figure()\n",
    "plot.scatter(x[:,0], x[:,1], c=y)\n",
    "plot.show()\n",
    "\n",
    "x_train, y_train = x[:1500], y[:1500]\n",
    "x_test, y_test = x[1500:], y[1500:]\n",
    "\n",
    "# sanity check\n",
    "assert len(x_train) == len(y_train) == 1500\n",
    "assert len(x_test) == len(y_test) == 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the model you used here, use latex math to write down equations.\n",
    "\n",
    "Model: $p_{+} = p(y = 1|x) = \\frac{1}{1 + e^{-w.x + b}}$, where $w, b \\in R^{d}$\n",
    "\n",
    "Distance Function: -$(y * log(p_{+}) + (1 - y) * log(1 - p_{+}))$\n",
    "\n",
    "Learning Rule: $w \\leftarrow w - \\eta * (\\hat{y} - y) * x$\n",
    "\n",
    "Hint: the model definition in scikit learn is very similar to what we did in the lab with perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAKE A MODEL HERE ###\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "myLogReg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning\n",
    "\n",
    "Perform the training of your model on your training dataset and report the accuracy/error here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kz882\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy rate is 0.9426666666666667\n"
     ]
    }
   ],
   "source": [
    "### DO THE TRAINING HERE ###\n",
    "myLogReg.fit(x_train,y_train)\n",
    "train_accuracy = myLogReg.score(x_train, y_train)\n",
    "print('Training accuracy rate is {}'.format(train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Do the analysis of your model here:\n",
    "\n",
    "compute the error rate on the test set, discuss the result. Can it be trained better? If not, why?\n",
    "\n",
    "You can plot the class boundary produced by your model to make your arguments stronger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy rate is 0.932\n"
     ]
    }
   ],
   "source": [
    "### DO THE ANALYSIS HERE ##\n",
    "test_accuracy = myLogReg.score(x_test, y_test)\n",
    "print('Test accuracy rate is {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn: 0.557 x_1 + 1.419 x_2 + 13.914 = 0\n"
     ]
    }
   ],
   "source": [
    "# get w and b from the model\n",
    "sk_w = numpy.concatenate((myLogReg.coef_.reshape(-1),myLogReg.intercept_.reshape(-1)))\n",
    "print('Sklearn: {:.3f} x_1 + {:.3f} x_2 + {:.3f} = 0'.format(*sk_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kz882\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:424: MatplotlibDeprecationWarning: \n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n"
     ]
    }
   ],
   "source": [
    "w = sk_w[:2] #weight\n",
    "b = sk_w[2]  #bias vector\n",
    "# visualize data \n",
    "def vis_data(x, y = None, c='r'):\n",
    "    if y is None: \n",
    "        y = [None] * len(x)\n",
    "    for x_, y_ in zip(x, y):\n",
    "        if y_ is None:\n",
    "            plot.plot(x_[0], x_[1], 'o', markerfacecolor='none', markeredgecolor=c)\n",
    "        else:\n",
    "            plot.plot(x_[0], x_[1], c+'o' if y_ == 0 else c+'+')\n",
    "    plot.grid('on')\n",
    "    \n",
    "def vis_hyperplane(w, b, typ='k--'):\n",
    "\n",
    "    lim0 = plot.gca().get_xlim()\n",
    "    lim1 = plot.gca().get_ylim()\n",
    "    m0, m1 = lim0[0], lim0[1]\n",
    "\n",
    "    intercept0 = -(w[0] * m0 + b)/w[1]\n",
    "    intercept1 = -(w[0] * m1 + b)/w[1]\n",
    "    \n",
    "    plt1, = plot.plot([m0, m1], [intercept0, intercept1], typ)\n",
    "\n",
    "    plot.gca().set_xlim(lim0)\n",
    "    plot.gca().set_ylim(lim1)\n",
    "        \n",
    "    return plt1\n",
    "\n",
    "plot.figure(figsize=(10,10))\n",
    "\n",
    "vis_data(x, y, c='r')\n",
    "\n",
    "plt1 = vis_hyperplane(w, b, 'k--')\n",
    "plot.legend([plt1], [\n",
    "        'Final: ${:.2} x_1 + {:.2} x_2 + {:.2} = 0$'.format(*list(w)+[b])],\n",
    "           loc='best')\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve the model by having a larger data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : SVM classifier with SciKit Learn\n",
    "\n",
    "In the second part of this practical section you have to implement *SVM classifier* using *scikit* learn library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Please use make_blob function as we did in the lab to produce some random datasets. Consider giving us a random_seed which you will use while reporting results in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c767f2824bd94a65975ebacca890a5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### MAKE A DATASET HERE ###\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "%matplotlib widget\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plot\n",
    "from tqdm import tqdm\n",
    "\n",
    "#random_seed = numpy.random.randint(0,100)\n",
    "random_seed = 1234\n",
    "\n",
    "x, y = make_blobs(n_samples=2000, centers=2, n_features=2,\n",
    "                  random_state=random_seed)\n",
    "plot.figure()\n",
    "plot.scatter(x[:,0], x[:,1], c=y)\n",
    "plot.show()\n",
    "\n",
    "x_train, y_train = x[:1500], y[:1500]\n",
    "x_test, y_test = x[1500:], y[1500:]\n",
    "\n",
    "# sanity check\n",
    "assert len(x_train) == len(y_train) == 1500\n",
    "assert len(x_test) == len(y_test) == 500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the model you used here, use latex math to write down equations\n",
    "\n",
    "\\begin{align}\\begin{aligned}\\min_ {w, b, \\zeta} \\frac{1}{2} w^T w + C \\sum_{i=1}^{n} \\zeta_i\\\\\\begin{split}\\textrm {subject to } & y_i (w^T \\phi (x_i) + b) \\geq 1 - \\zeta_i,\\\\\n",
    "& \\zeta_i \\geq 0, i=1, ..., n\\end{split}\\end{aligned}\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAKE A MODEL HERE ###\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001,kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning\n",
    "\n",
    "Perform the training of your model on your training dataset and report the accuracy/error here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error rate 0.9993333333333333\n"
     ]
    }
   ],
   "source": [
    "### DO THE TRAINING HERE ###\n",
    "clf.fit(x_train, y_train)\n",
    "train_error2 = clf.score(x_train, y_train)\n",
    "print('Training error rate {}'.format(train_error2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Do the analysis of your model here:\n",
    "\n",
    "compute the error rate on the test set, discuss the result. Can it be trained better? If not, why?\n",
    "\n",
    "You can plot the class boundary priduced by your model to make your arguments stronger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy rate 1.0\n"
     ]
    }
   ],
   "source": [
    "### DO THE ANALYSIS HERE ###\n",
    "test_accuracy2 = clf.score(x_test, y_test)\n",
    "print('Test accuracy rate {}'.format(test_accuracy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn: 1.458 x_1 + 1.297 x_2 + 0.395 = 0\n"
     ]
    }
   ],
   "source": [
    "SVM_w = numpy.concatenate((clf.coef_.reshape(-1),clf.intercept_.reshape(-1)))\n",
    "print('Sklearn: {:.3f} x_1 + {:.3f} x_2 + {:.3f} = 0'.format(*SVM_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f658c8469fbb4cdda7b1c584a1110281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kz882\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:424: MatplotlibDeprecationWarning: \n",
      "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n"
     ]
    }
   ],
   "source": [
    "w = SVM_w[:2] #weight\n",
    "b = SVM_w[2]  #bias vector\n",
    "# visualize data \n",
    "def vis_data(x, y = None, c='r'):\n",
    "    if y is None: \n",
    "        y = [None] * len(x)\n",
    "    for x_, y_ in zip(x, y):\n",
    "        if y_ is None:\n",
    "            plot.plot(x_[0], x_[1], 'o', markerfacecolor='none', markeredgecolor=c)\n",
    "        else:\n",
    "            plot.plot(x_[0], x_[1], c+'o' if y_ == 0 else c+'+')\n",
    "    plot.grid('on')\n",
    "    \n",
    "\n",
    "plot.figure(figsize=(10,10))\n",
    "\n",
    "vis_data(x, y, c='r')\n",
    "\n",
    "plt1 = vis_hyperplane(w, b, 'k--')\n",
    "plot.legend([plt1], [\n",
    "        'Final: ${:.2} x_1 + {:.2} x_2 + {:.2} = 0$'.format(*list(w)+[b])],\n",
    "           loc='best')\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve the model by tuning parameters. I found some resources here, but I don't think other points apply to the SVM model individually.\n",
    "https://stackoverflow.com/questions/38077190/how-to-increase-the-model-accuracy-of-logistic-regression-in-scikit-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
